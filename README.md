<h1 align='center' style="text-align:center; font-weight:bold; font-size:2.0em;letter-spacing:2.0px;">
                A Recipe for Watermarking Diffusion Models</h1>
<p align='center' style="text-align:center;font-size:1.25em;">
    <a href="https://scholar.google.com/citations?user=kQA0x9UAAAAJ&hl=en" target="_blank" style="text-decoration: none;">Yunqing Zhao<sup>1</sup> </a>&nbsp;/&nbsp;
    <a href="https://p2333.github.io/" target="_blank" style="text-decoration: none;">Tianyu Pang <sup>2</sup> </a>&nbsp;/&nbsp;
    <a href="https://duchao0726.github.io/" target="_blank" style="text-decoration: none;">Chao Du <sup>2</sup> </a>&nbsp;/&nbsp;
    <a href="https://ml.cs.tsinghua.edu.cn/~xiaoyang/" target="_blank" style="text-decoration: none;">Xiao Yang <sup>3</sup> </a>&nbsp;/&nbsp;<br/>
    <a href="https://sites.google.com/site/mancheung0407/" target="_blank" style="text-decoration: none;">Ngai&#8209;Man Cheung <sup>1</sup> </a>&nbsp;/&nbsp;
    <a href="https://linmin.me/" target="_blank" style="text-decoration: none;">Min Lin <sup>2</sup> </a></br></br>
<sup>1</sup>Singapore University of Technology and Design&emsp;
<sup>2</sup>Sea AI Lab&emsp;
<sup>3</sup>Tsinghua University
<br/>
<b>
<em>arXiv Pre-print, 2023</em> <br>
</b>
</p>

<p align='center';>
<b>
<!-- <em>The Thirty-Sixth Annual Conference on Neural Information Processing Systems (NeurIPS 2022);</em> -->
</b>
</p>

<p align='center' style="text-align:center;font-size:2.5 em;">
<b>
    <a href="https://github.com/yunqing-me/WatermarkDM/" target="_blank" style="text-decoration: none;">Project Page</a>&nbsp;/&nbsp;
    <a href="https://arxiv.org/pdf/2303.10137.pdf" target="_blank" style="text-decoration: none;">arXiv</a> 
    <!-- /&nbsp; -->
    <!-- <a href="https://arxiv.org/abs/2208.10930" target="_blank" style="text-decoration: none;">Data Repository</a>&nbsp; -->

</b>
</p>

### Code and Project Page are actively updated...stay tuned!



# Unconditional/class-conditional Diffusion Models

<!-- ## Installation and Environment:
- Platform: Linux
- Hardware Type: A100 PCIe 40GB & CuDNN 11.4 -->

A suitable conda environment named ```noise2img``` can be created and activated with:

```
conda env create -f noise2img.yaml
conda activate noise2img
```


# Text-to-Image Diffusion Models

A suitable conda environment named ```ldm``` can be created and activated with:

```
conda env create -f environment.yaml
conda activate ldm
```







## Citation
If you find this project useful in your research, please consider citing our paper:
  ```
@article{zhao2023recipe,
    title={A Recipe for Watermarking Diffusion Models},
    author={Zhao, Yunqing and Pang, Tianyu and Du, Chao and Yang, Xiao and Cheung, Ngai-Man and Lin, Min},
    journal={arXiv preprint arXiv:2303.10137},
    year={2023}
}
  ```